# ğŸ’¬ Chatbot for Any Website using Gemini Pro, LlamaIndex & Pinecone

This project is an advanced Retrieval-Augmented Generation (RAG) chatbot built using **Google's Gemini Pro**, **LlamaIndex**, and **Pinecone**. It loads content from any public website, indexes it, and allows users to query the content through a natural language interface.

---

## ğŸš€ Features

- ğŸ”— Scrape and parse content from any website URL
- ğŸ§  Semantic search using vector embeddings (Google GenAI)
- ğŸª Vector storage in Pinecone
- ğŸ’¡ Intelligent and detailed answers using Gemini Pro
- ğŸ“¦ Supports persistent storage and reusability of existing vector index
- ğŸ§© Modular design using LlamaIndex for easy customization

---

## ğŸ“‚ Project Structure

```
ğŸ“ chatbot-website-rag
â”œâ”€â”€ main.py               # Main script for indexing and querying
â”œâ”€â”€ .env                  # Stores API keys
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ README.md             # You're reading this!
```

---

## ğŸ”§ Setup Instructions

### 1. Clone the repository

```bash
git clone https://github.com/yourusername/chatbot-website-rag.git
cd chatbot-website-rag
```

### 2. Install dependencies

```bash
pip install -r requirements.txt
```

### 3. Create a `.env` file

Create a `.env` file in the root directory and add your API keys:

```
GOOGLE_API_KEY=your_google_api_key
PINECONE_API_KEY=your_pinecone_api_key
```

> ğŸ”‘ You need access to [Google's GenAI API](https://makersuite.google.com/app) and a [Pinecone](https://www.pinecone.io/start/) account.

### 4. Run the chatbot

```bash
python main.py
```

You will be prompted to enter a question after the indexing or loading process.

---

## ğŸ›  How It Works

1. **Scraping Content**: Uses `BeautifulSoupWebReader` from LlamaIndex to load and parse a webpage.
2. **Text Chunking**: Splits content into clean semantic chunks using `SentenceSplitter`.
3. **Embedding & Indexing**: Generates vector embeddings using Gemini Pro and stores them in Pinecone.
4. **Query Engine**: Retrieves relevant chunks and generates a detailed answer using a custom prompt and Gemini Pro.

---

## ğŸ§  Technologies Used

- [Google Gemini Pro (LLM & Embeddings)](https://ai.google.dev/)
- [LlamaIndex](https://www.llamaindex.ai/)
- [Pinecone Vector DB](https://www.pinecone.io/)
- Python 3.8+

---

## ğŸ“ Customization

- ğŸ” Change `DATA_URL` to scrape a different webpage.
- âš™ï¸ Adjust `chunk_size`, `chunk_overlap`, or `similarity_top_k` for performance tuning.
- ğŸ—¨ Modify `qa_prompt_tmpl` to personalize the tone and structure of responses.

---

## ğŸ“ˆ Use Cases

- Build an FAQ bot for any documentation
- Customer support assistant for product pages
- Internal knowledge base search
- Educational Q&A system

---

## ğŸ™Œ Acknowledgements

- Inspired by tutorials and community examples using LlamaIndex + Pinecone + GenAI
- Powered by open-source tools and APIs

---

## ğŸ“„ License

MIT License. Feel free to use, share, and contribute.

---
